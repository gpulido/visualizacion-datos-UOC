{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install matplotlib-venn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = {'Monthly': 12, 'Yearly': 1, 'Weekly':52}\n",
    "\n",
    "def comp_level(x):\n",
    "    if x.CompFreq != x.CompFreq:\n",
    "        return x.CompFreq\n",
    "    return x.CompTotal * comp[x.CompFreq] / x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "year = 2021\n",
    "colworked = 'LanguageHaveWorkedWith'\n",
    "colwanted = 'LanguageWantToWorkWith'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos y mostramos su contenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "year = 2021\n",
    "colworked = 'LanguageHaveWorkedWith'\n",
    "colwanted = 'LanguageWantToWorkWith'\n",
    "\n",
    "# year = 2020\n",
    "# colworked = 'LanguageWorkedWith'\n",
    "# colwanted = 'LanguageDesireNextYear'\n",
    "\n",
    "\n",
    "# year = 2019\n",
    "# colworked = 'LanguageWorkedWith'\n",
    "# colwanted = 'LanguageDesireNextYear'\n",
    "\n",
    "# year = 2018\n",
    "# colworked = 'LanguageWorkedWith'\n",
    "# colwanted = 'LanguageDesireNextYear'\n",
    "\n",
    "# year = 2017\n",
    "# colworked = 'HaveWorkedLanguage'\n",
    "# colwanted = 'WantWorkLanguage'\n",
    "\n",
    "# year = 2016\n",
    "# colworked = 'tech_do'\n",
    "# colwanted = 'tech_want'\n",
    "\n",
    "\n",
    "zf = zipfile.ZipFile(f'data/in/stack-overflow-developer-survey-{year}.zip') \n",
    "devs = pd.read_csv(zf.open('survey_results_public.csv'))\n",
    "# Cargamos los ratios de conversion de las monedas a 1 de Diciembre de cada año.\n",
    "with open(f'data/rates/rates-{year}.json', 'r') as f:\n",
    "  data = json.loads(f.read())\n",
    "rates = pd.json_normalize(data['rates']).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos los nulos de las dos  propiedades que nos intersan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "devs[colworked] = devs[colworked].fillna(\"\")\n",
    "devs[colwanted] = devs[colwanted].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_worked = devs[colworked].str.replace(' ', '').str.get_dummies(sep=';')\n",
    "lang_want = devs[colwanted].str.replace(' ', '').str.get_dummies(sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se nivela la compensacion para obtener el valor anual aproximado en USD, aplicando el cambio de divisa cargado del año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "devs.Currency = devs.Currency.str[:3]\n",
    "devs = pd.merge(devs, rates, left_on='Currency', right_index=True)\n",
    "devs['CompTotalUSD'] = devs.apply(comp_level, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos el dataframe con los distintos lenguajes y su compensacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "comps = lang_worked.multiply( devs['CompTotalUSD']/1000, axis=\"index\").round(decimals=0).replace(0, np.NaN).median().astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos el porcentaje de uso de cada lenguaje respecto del total.\n",
    "Como vamos a comparar años distintos con encuestados distintos por año, el porcentaje anual es una forma de nivelar y poder realizar la comparacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "worked = lang_worked.sum() / len(lang_worked)\n",
    "wanted = lang_want.sum() / len(lang_want)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unimos los dataframes de lenguajes trabajados en el año, lenguajes en los que se quiere trabajar, la compensacion y el año."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_df = pd.DataFrame(worked, columns= ['Worked'])\n",
    "wa_df = pd.DataFrame(wanted, columns= ['Wanted'])\n",
    "langs = pd.concat([w_df, wa_df, comps], axis=1)\n",
    "langs['Year'] = year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportamos los datos procesados del año."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs.to_csv(f'data/out/{year}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "9e4d46cb2e7439cd377379e4187049771cc0b6089dc8d4ad323c0b3c23302069"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
